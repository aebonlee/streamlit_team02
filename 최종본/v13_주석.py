import os, io, re, json, textwrap, datetime
from typing import Optional, List, Dict, Tuple

import streamlit as st

# ===== Optional libraries =====
# pandas, numpy: ë°ì´í„°í”„ë ˆì„ ë° ìˆ˜ì¹˜ ê³„ì‚°ìš©
try:
    import pandas as pd
    import numpy as np
    PANDAS_OK = True
except Exception:
    PANDAS_OK = False  # ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆì„ ë•Œ False ì²˜ë¦¬

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import altair as alt
    import plotly.express as px
    VIZ_OK = True
except Exception:
    VIZ_OK = False

# ì›¹ ìš”ì²­/í¬ë¡¤ë§
try:
    import requests
    from bs4 import BeautifulSoup
    HTTP_OK = True
except Exception:
    HTTP_OK = False

# docx íŒŒì¼ ì½ê¸°
try:
    from docx import Document
    DOCX_OK = True
except Exception:
    DOCX_OK = False

# PDF ìƒì„±
try:
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph
    from reportlab.lib.styles import getSampleStyleSheet
    REPORTLAB_OK = True
except Exception:
    REPORTLAB_OK = False

# LLM (OpenAI) ê´€ë ¨
try:
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain.chains import LLMChain
    LLM_OK = True
except Exception:
    LLM_OK = False

# ================= ì„¸ì…˜ ì´ˆê¸°í™” =================
# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    # AI ì²« ì¸ì‚¬ ë©”ì‹œì§€
    st.session_state.messages = [
        {
            "role": "ai",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            "time": datetime.datetime.now().strftime("%H:%M"),
        }
    ]
if "saved_files" not in st.session_state:
    st.session_state.saved_files = []  # ì—…ë¡œë“œëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
if "api_key" not in st.session_state:
    st.session_state.api_key = os.getenv("OPENAI_API_KEY", "")  # í™˜ê²½ë³€ìˆ˜ OpenAI í‚¤
if "basic_settings" not in st.session_state:
    st.session_state.basic_settings = {
        "model": "GPT-4 (ë¬´ë£Œ)",  # ê¸°ë³¸ ëª¨ë¸
        "tone": "ì „ë¬¸ì ",        # ë¬¸ì²´
        "length": 800,           # ì¶œë ¥ ê¸¸ì´
    }
if "advanced_settings" not in st.session_state:
    st.session_state.advanced_settings = {
        "creativity": 0.5,        # ì°½ì˜ì„± ì •ë„
        "export_format": "PDF ë¬¸ì„œ",  # ë‚´ë³´ë‚´ê¸° í˜•ì‹
    }
if "show_guide" not in st.session_state:
    st.session_state.show_guide = False  # ê°€ì´ë“œ í‘œì‹œ ì—¬ë¶€

# ================= ê°€ì´ë“œë¼ì¸ =================
GUIDE = """ğŸ“ **AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜ ì‚¬ìš© ê°€ì´ë“œ**
1) **ìì†Œì„œ í‰ê°€ íƒ­**ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ê³ , íšŒì‚¬/ì§ë¬´ë¥¼ ì…ë ¥ í›„ **í‰ê°€ ì‹¤í–‰**
   - ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ + LLM ê°œì„ ì•ˆ + ìŠ¤í‚¬ ë§¤ì¹­ í‘œ ì œê³µ
2) **íŠ¸ë Œë“œ/ê¸°ì—… íƒ­**ì—ì„œ íšŒì‚¬/ì§ë¬´ ì…ë ¥ â†’ ìµœì‹  ê³µê³ /ê¸°ìˆ  ì¶”ì´ì™€ íšŒì‚¬ ì¸ì¬ìƒ ìš”ì•½
3) ì¢Œì¸¡ **ì„¤ì •**ì—ì„œ OpenAI ë° (ì„ íƒ) SERP/Bing í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ì›¹ ìš”ì•½ ê¸°ëŠ¥ í™œì„±í™”
4) (ì„ íƒ) Tableau Public ë§í¬ê°€ ìˆë‹¤ë©´ íƒ­ í•˜ë‹¨ì— ì„ë² ë“œí•˜ì—¬ íŒ€ê³¼ ê³µìœ  ê°€ëŠ¥

ğŸ“¡ **ìƒˆ ê¸°ëŠ¥ ì•ˆë‚´**
ì±„íŒ…ì°½ì— **"ë‚´ê°€ (íšŒì‚¬ëª…)ì˜ ìì†Œì„œì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì–»ê³  ì‹¶ì–´"** ë¼ê³  ì…ë ¥í•˜ë©´,
ë¡œì»¬ CSVë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ê¸°ì—…ì˜ **ì±„ìš©/ê¸°ìˆ  ìˆ˜ìš” ìš”ì•½**ì„ ë°”ë¡œ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤!
"""

def get_guideline() -> str:
    return GUIDE  # ê°€ì´ë“œ í…ìŠ¤íŠ¸ ë°˜í™˜

# ================= ë°ì´í„° ê²½ë¡œ/í—¬í¼ =================
def _env(key: str, default: str = "") -> str:
    return os.getenv(key, default)  # í™˜ê²½ë³€ìˆ˜ ì½ê¸°

@st.cache_data(show_spinner=False)
def _default_data_dir() -> str:
    # ê¸°ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
    if os.path.isdir("/mnt/data"):
        return "/mnt/data"
    return _env("DATA_DIR", "./data")

DATA_DIR = _default_data_dir()  # ë°ì´í„° í´ë” ê²½ë¡œ

@st.cache_data(show_spinner=False)
def load_csv(name: str) -> Optional[pd.DataFrame]:
    # CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if not PANDAS_OK:
        return None
    candidates = [os.path.join(DATA_DIR, name), os.path.join(".", name)]
    for path in candidates:
        if os.path.isfile(path):
            try:
                return pd.read_csv(path)
            except Exception:
                pass
    return None

# ë°ì´í„° ë¡œë“œ
if PANDAS_OK:
    job_market = load_csv("job_market.csv")          # ì±„ìš©ì‹œì¥ ë°ì´í„°
    macro = load_csv("macro_indicators.csv")        # ê±°ì‹œ ì§€í‘œ
    skills = load_csv("skills_analysis.csv")        # ìŠ¤í‚¬ ë¶„ì„
    tech_trends = load_csv("tech_trends.csv")       # ê¸°ìˆ  íŠ¸ë Œë“œ
else:
    job_market = macro = skills = tech_trends = None

# ================= í…ìŠ¤íŠ¸/ë¬¸ì„œ ì²˜ë¦¬ =================
def read_text_from_upload(uploaded) -> str:
    # ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì½ê¸°
    if uploaded is None:
        return ""
    name = uploaded.name.lower()
    try:
        if name.endswith(".txt"):
            return uploaded.read().decode("utf-8", errors="ignore")
        if name.endswith(".docx") and DOCX_OK:
            doc = Document(uploaded)
            return "\n".join(p.text for p in doc.paragraphs)
        return uploaded.read().decode("utf-8", errors="ignore")
    except Exception as e:
        return f"[íŒŒì¼ ì½ê¸° ì˜¤ë¥˜] {e}"

# ================= ê·œì¹™ ê¸°ë°˜ ìŠ¤ì½”ì–´ëŸ¬ =================
# í–‰ë™ ë™ì‚¬ ëª©ë¡: ì„±ê³¼/ëŠ¥ë ¥ í‘œí˜„
ACTION_WORDS = [
    "ê°œì„ ", "ìµœì í™”", "ì„¤ê³„", "êµ¬í˜„", "ë¶„ì„", "ìë™í™”", "í˜‘ì—…", "ë¦¬íŒ©í„°", "ê²€ì¦",
    "ì„±ê³¼", "ì¦ê°€", "ê°ì†Œ", "ë‹¬ì„±", "ê¸°ì—¬", "í•´ê²°", "ë¦¬ë”", "ì¡°ìœ¨",
]
# STAR ê¸°ë²• í† í°
STAR_TOKENS = ["ìƒí™©", "ê³¼ì œ", "í–‰ë™", "ê²°ê³¼", "Situation", "Task", "Action", "Result"]
# ë¶ˆí•„ìš”í•˜ê²Œ ë°˜ë³µë˜ëŠ” ë‹¨ì–´
FILLERS = ["ìµœëŒ€í•œ", "ì •ë§", "ë§¤ìš°", "ë‹¤ì–‘í•œ", "ë§ì€", "ì—´ì •", "ì„±ì‹¤", "ë…¸ë ¥"]
# ìˆ«ì/ë°±ë¶„ìœ¨ ì •ê·œí‘œí˜„
NUM_RE = re.compile(r"(?<!\w)(?:[0-9]+(?:\.[0-9]+)?%?|[ì¼ì´ì‚¼ì‚¬ì˜¤ìœ¡ì¹ íŒ”êµ¬ì‹­]+%?)(?!\w)")

def tokenize_kr(text: str) -> List[str]:
    # í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ ë‹¨ìœ„ í† í°í™”
    return re.findall(r"[\wê°€-í£%]+", text.lower())

def skill_coverage(text: str, skills_df: Optional[pd.DataFrame], month: Optional[str] = None) -> Tuple[float, List[str]]:
    # ìŠ¤í‚¬ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
    if skills_df is None or len(skills_df) == 0:
        return 0.0, []
    toks = set(tokenize_kr(text))
    df = skills_df.copy()
    if month and "month" in df.columns:
        df = df[df["month"] == month] if (df["month"] == month).any() else df
    listed = [str(s).lower() for s in df["skill"].unique().tolist()]
    matched = sorted({s for s in listed if any(s in t for t in toks)})
    cov = len(matched) / max(1, len(set(listed)))
    return cov, matched[:20]

def compute_resume_scores(text: str, role: str = "", company: str = "", skills_df: Optional[pd.DataFrame] = None) -> Dict[str, float]:
    # ìê¸°ì†Œê°œì„œ ì ìˆ˜ ê³„ì‚°
    tokens = tokenize_kr(text)
    n_words = len(tokens)
    n_chars = len(text)
    nums = NUM_RE.findall(text)  # ìˆ«ì ë“±ì¥ ë¹ˆë„
    metric_density = min(1.0, len(nums) / max(1, n_words) * 10)  # ìˆ«ì ë°€ë„ ìŠ¤ì½”ì–´
    action_hits = sum(1 for w in ACTION_WORDS if any(w in t for t in tokens))  # í–‰ë™ ë™ì‚¬ ì‚¬ìš© íšŸìˆ˜
    action_score = min(1.0, action_hits / 6)
    star_hits = sum(1 for w in STAR_TOKENS if any(w.lower() in t for t in tokens))  # STAR ê¸°ë²• ì‚¬ìš©
    star_score = min(1.0, star_hits / 4)
    filler_hits = sum(tokens.count(f.lower()) for f in FILLERS)  # ë¶ˆí•„ìš” ë‹¨ì–´ ì¹´ìš´íŠ¸
    filler_penalty = min(0.3, filler_hits / max(1, n_words) * 5)  # í˜ë„í‹°
    length_score = 1.0 if 600 <= n_chars <= 1200 else max(0.3, 1 - abs(n_chars - 900) / 1200)  # ê¸¸ì´ ì ì ˆì„±
    month = None
    if skills_df is not None and "month" in skills_df.columns:
        month = skills_df["month"].max()
    cov, matched = skill_coverage(text, skills_df, month)  # ìŠ¤í‚¬ ì»¤ë²„ë¦¬ì§€
    coverage_score = min(1.0, 0.5 + cov)
    # ê°€ì¤‘ì¹˜ ì„¤ì •
    weights = {
        "metrics": 0.25,
        "action": 0.15,
        "star": 0.15,
        "length": 0.15,
        "coverage": 0.30,
    }
    # ì¢…í•© ì ìˆ˜ ê³„ì‚°
    total = (
        metric_density * weights["metrics"]
        + action_score * weights["action"]
        + star_score * weights["star"]
        + length_score * weights["length"]
        + coverage_score * weights["coverage"]
    )
    total = max(0.0, min(1.0, total - filler_penalty))  # í˜ë„í‹° ì ìš©
    return {
        "ì´ì (0-100)": round(total * 100, 1),
        "ì„±ê³¼(ìˆ«ì)ë°€ë„": round(metric_density, 3),   # <- ì—¬ê¸°ê¹Œì§€ ì£¼ì„ ì™„ë£Œ
    }
"í–‰ë™ì„±": round(action_score, 3),  # ACTION_WORDS ê¸°ë°˜ ì ìˆ˜, ìê¸°ì†Œê°œì„œì—ì„œ êµ¬ì²´ì  í–‰ë™ì„ ì–¼ë§ˆë‚˜ ê°•ì¡°í–ˆëŠ”ì§€
"STARêµ¬ì¡°": round(star_score, 3),  # STAR êµ¬ì¡°(Situation, Task, Action, Result) ì¤€ìˆ˜ ì •ë„
"ê¸¸ì´ì ì •": round(length_score, 3),  # ê¸€ ê¸¸ì´ê°€ ì ì ˆí•œì§€ ì ìˆ˜í™”
"ìŠ¤í‚¬ì»¤ë²„ë¦¬ì§€": round(coverage_score, 3),  # ìŠ¤í‚¬ ë§¤ì¹­ ì»¤ë²„ë¦¬ì§€ ì ìˆ˜
"êµ°ë”ë”ê¸°ê°ì ": round(filler_penalty, 3),  # êµ°ë”ë”ê¸°/ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì‚¬ìš©ì— ë”°ë¥¸ ê°ì 
}

def llm_improve(text: str, role: str, company: str, tone: str, length: int) -> str:
    # LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ê¸°ë°˜ ìê¸°ì†Œê°œì„œ ê°œì„  í•¨ìˆ˜
    if not LLM_OK or not st.session_state.get("api_key"):
        # LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
        return "[LLM ë¯¸ì‚¬ìš©] OpenAI API í‚¤ê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •: í†¤, ìµœëŒ€ ê¸¸ì´, STAR êµ¬ì¡° ì ìš© ë“±
    system = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì²¨ì‚­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    - í†¤: {tone}
    - ìµœëŒ€ ê¸¸ì´: {length}ì
    - ì‘ì—…: ì•„ë˜ ìê¸°ì†Œê°œì„œë¥¼ {company} {role} ì§€ì› ê¸°ì¤€ìœ¼ë¡œ STAR êµ¬ì¡°ì™€ ìˆ˜ì¹˜ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë“¬ê³ , ì¤‘ë³µ/êµ°ë”ë”ê¸°ë¥¼ ì¤„ì´ì„¸ìš”.
    - ì¶œë ¥ í˜•ì‹: 1) ê°œì„  ìš”ì•½(ë¶ˆë¦¿) 2) ê°œì„ ëœ ìê¸°ì†Œê°œì„œ(ë¬¸ë‹¨) 3) ë‹¤ìŒ ì•¡ì…˜ 3ê°€ì§€"""
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    tmpl = ChatPromptTemplate.from_messages([("system", system), ("human", "ì›ë¬¸:\n{orig}")])
    
    # LLM ì²´ì¸ êµ¬ì„±
    chain = LLMChain(
        llm=ChatOpenAI(
            api_key=st.session_state.get("api_key", os.getenv("OPENAI_API_KEY")),
            model="gpt-4o-mini",  # ì‚¬ìš©í•  ëª¨ë¸
            temperature=0.4,      # ì°½ì˜ì„± ì •ë„
        ),
        prompt=tmpl,
    )
    
    # LLM í˜¸ì¶œ
    out = chain.invoke({"orig": text})
    return out.get("text", str(out))  # ê²°ê³¼ ë°˜í™˜

# ================= ì±„íŒ…ìš© ê¸°ëŠ¥ =================
COMPANY_CMD_RE = re.compile(
    r"ë‚´ê°€\s*(?P<company>.+?)\s*ì˜?\s*ìì†Œì„œì—\s*ëŒ€í•œ\s*ë°ì´í„°(?:ë¥¼)?\s*ì–»ê³ \s*ì‹¶ì–´",
    re.IGNORECASE,
)  # ì‚¬ìš©ì ì…ë ¥ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ ì •ê·œì‹

def _clean_company(s: str) -> str:
    # íšŒì‚¬ëª… ë¬¸ìì—´ ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
    s = s.strip()
    s = re.sub(r'^[\"â€œâ€â€˜â€™\'(\[]+', "", s)
    s = re.sub(r'[\"â€œâ€â€˜â€™\'\])]+$', "", s)
    return s.strip()

def try_parse_company_query(text: str) -> Optional[str]:
    # ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ íšŒì‚¬ëª… íŒŒì‹±
    if not text:
        return None
    m = COMPANY_CMD_RE.search(text)
    if not m:
        return None
    return _clean_company(m.group("company"))

def summarize_company_from_csvs(company: str) -> str:
    # ë¡œì»¬ CSV ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íšŒì‚¬ ìì†Œì„œ ìš”ì•½
    if not PANDAS_OK:
        return (
            f"### ğŸ“Š ê¸°ì—… ìì†Œì„œ ë°ì´í„° ìš”ì•½ â€” {company}\n"
            "- ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ `pandas` ì„¤ì¹˜ê°€ í•„ìš”í•´ìš”. `pip install pandas` í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n"
        )
    lines = [f"### ğŸ“Š ê¸°ì—… ìì†Œì„œ ë°ì´í„° ìš”ì•½ â€” {company}"]
    
    # job_market.csv ê¸°ë°˜ ê³µê³  ìˆ˜ í™•ì¸
    if job_market is not None:
        sub = job_market.copy()
        if "company" in sub.columns:
            sub = sub[sub["company"].astype(str).str.contains(company, case=False, na=False)]
        try:
            cnt = sub["job_code"].nunique() if "job_code" in sub.columns else len(sub)
        except Exception:
            cnt = len(sub)
        recent = ""
        if "posted_date" in sub.columns:
            try:
                _d = pd.to_datetime(sub["posted_date"], errors="coerce")
                if _d.notna().any():
                    recent = _d.max().date().isoformat()
            except Exception:
                pass
        msg = f"- ìµœê·¼ ìˆ˜ì§‘ ê³µê³  ìˆ˜: **{cnt}ê±´**"
        if recent:
            msg += f" (ìµœì‹ : {recent})"
        lines.append(msg)
    else:
        lines.append("- `job_market.csv`ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `/mnt/data` ë˜ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë°°ì¹˜í•´ì£¼ì„¸ìš”.")
    
    # skills_analysis.csv ê¸°ë°˜ ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš”
    if skills is not None and "skill" in skills.columns:
        kdf = skills.copy()
        if "month" in kdf.columns and kdf["month"].notna().any():
            top_month = kdf["month"].max()
            if (kdf["month"] == top_month).any():
                kdf = kdf[kdf["month"] == top_month]
        try:
            if "job_count" in kdf.columns:
                top_skills = (
                    kdf.groupby("skill")["job_count"].sum().sort_values(ascending=False).head(10).index.tolist()
                )
            else:
                top_skills = kdf["skill"].value_counts().head(10).index.tolist()
        except Exception:
            top_skills = []
        if top_skills:
            lines.append(f"- ìµœê·¼ ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš”: {', '.join(top_skills)}")
    else:
        lines.append("- `skills_analysis.csv`ë¥¼ ì°¾ì§€ ëª»í•´ ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš”ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return "\n".join(lines) + "\n\n> *ì°¸ê³ : ë°ì´í„°ëŠ” ë¡œì»¬ CSV ê¸°ì¤€ ìš”ì•½ì´ë©°, ë” ìì„¸í•œ ì›¹ ë¦¬ì„œì¹˜ëŠ” ì„ íƒì ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.*"

# ===== ì›¹ ë™í–¥/ê¸°ì—… ì¸ì¬ìƒ ìˆ˜ì§‘ =====
def search_web(query: str, topk: int = 5) -> List[Dict[str, str]]:
    # Google SERP ë˜ëŠ” Bing APIë¥¼ í†µí•´ ì›¹ ê²€ìƒ‰
    res: List[Dict[str, str]] = []
    serp_key = os.getenv("SERPAPI_API_KEY")
    bing_key = os.getenv("BING_API_KEY")
    try:
        if serp_key:
            params = {"engine": "google", "q": query, "api_key": serp_key, "num": topk, "hl": "ko"}
            r = requests.get("https://serpapi.com/search.json", params=params, timeout=15)
            j = r.json()
            for it in j.get("organic_results", [])[:topk]:
                res.append({"title": it.get("title", ""), "url": it.get("link", ""), "snippet": it.get("snippet", "")})
        elif bing_key:
            headers = {"Ocp-Apim-Subscription-Key": bing_key}
            r = requests.get(
                "https://api.bing.microsoft.com/v7.0/search",
                params={"q": query, "count": topk, "mkt": "ko-KR"},
                headers=headers,
                timeout=15,
            )
            j = r.json()
            for it in j.get("webPages", {}).get("value", [])[:topk]:
                res.append({"title": it.get("name", ""), "url": it.get("url", ""), "snippet": it.get("snippet", "")})
        return res
    except Exception:
        return res

def fetch_and_summarize(urls: List[str]) -> str:
    # URL ë¦¬ìŠ¤íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ í›„ ìš”ì•½
    texts = []
    for u in urls[:5]:
        try:
            html = requests.get(u, timeout=15).text
            soup = BeautifulSoup(html, "html.parser")
            t = " ".join([p.get_text(" ", strip=True) for p in soup.find_all(["p", "li"])])
            texts.append(textwrap.shorten(t, 3000))
        except Exception:
            pass
    joined = "\n\n".join(texts) if texts else ""
    if not joined:
        return "(ì›¹ í˜ì´ì§€ì—ì„œ ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.)"
    
    # LLM ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìš”ì•½ ìƒì„±
    if LLM_OK and os.getenv("OPENAI_API_KEY"):
        sys = "ë„ˆëŠ” ë¦¬ì„œì¹˜ ìš”ì•½ê°€ë‹¤. í•œêµ­ì–´ë¡œ 5ê°œ ë¶ˆë¦¿, 5ì¤„ ì´í•˜ ìš”ì•½ìœ¼ë¡œ ì •ë¦¬í•˜ë¼."
        tmpl = ChatPromptTemplate.from_messages([("system", sys), ("human", "ë‹¤ìŒ ìë£Œë¥¼ ìš”ì•½:\n{t}")])
        out = LLMChain(llm=ChatOpenAI(model="gpt-4o-mini", temperature=0.2), prompt=tmpl).invoke({"t": joined})
        return out.get("text", str(out))
    return joined[:1500]

def company_persona_and_requirements(company: str, role: str) -> Dict[str, str]:
    # íšŒì‚¬ ì¸ì¬ìƒ ë° ìš”êµ¬ì—­ëŸ‰ ìš”ì•½
    result = {"ì¸ì¬ìƒ": "", "ìš”êµ¬ì—­ëŸ‰": "", "ì¶œì²˜": []}
    if not HTTP_OK:
        return result
    queries = [
        f"{company} ì¸ì¬ìƒ site:co.kr OR site:com OR site:kr",
        f"{company} ì±„ìš© {role} ìê¸°ì†Œê°œì„œ",
        f"{company} core values culture",
    ]
    urls = []
    for q in queries:
        hits = search_web(q, topk=5)
        urls.extend([h["url"] for h in hits])
        result["ì¶œì²˜"].extend(hits)
    urls = list(dict.fromkeys([u for u in urls if u]))  # ì¤‘ë³µ ì œê±°
    summary = fetch_and_summarize(urls)
    result["ì¸ì¬ìƒ"] = summary
    
    # ìŠ¤í‚¬ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš”êµ¬ì—­ëŸ‰ ì˜ˆì‹œ ì¶”ê°€
    if skills is not None and "skill" in skills.columns:
        top_month = skills["month"].max() if "month" in skills.columns else None
        kdf = skills.copy()
        if top_month:
            kdf = kdf[kdf["month"] == top_month]
        top_skills = (
            kdf.groupby("skill")["job_count"].sum().sort_values(ascending=False).head(10).index.tolist()
            if "job_count" in kdf.columns
            else kdf["skill"].value_counts().head(10).index.tolist()
        )
        result["ìš”êµ¬ì—­ëŸ‰"] = "ìµœê·¼ ìˆ˜ìš” ìƒìœ„ ê¸°ìˆ  ì˜ˆì‹œ: " + ", ".join(top_skills)
    return result

# ================= AI ì‘ë‹µ ìƒì„± =================
def get_ai_response(user_input: str, uploaded_file=None) -> str:
    # ê°€ì´ë“œ í‚¤ì›Œë“œ ì²˜ë¦¬
    guideline_keywords = ["ê°€ì´ë“œ", "ê°€ì´ë“œë¼ì¸", "ë„ì›€ë§", "ì‚¬ìš©ë²•", "ì–´ë–»ê²Œ"]
    if any(keyword in user_input for keyword in guideline_keywords):
        return get_guideline()
    
    # ê¸°ë³¸ í…œí”Œë¦¿
    if not st.session_state.basic_settings or not LLM_OK or not st.session_state.get("api_key"):
        templates = {
            "default": """ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!
êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”:
â€¢ ì–´ë–¤ ì§ë¬´ì— ì§€ì›í•˜ì‹œë‚˜ìš”?
â€¢ ì–´ë–¤ ë¶€ë¶„ì´ ì–´ë ¤ìš°ì‹ ê°€ìš”?
â€¢ íŠ¹ë³„íˆ ê°•ì¡°í•˜ê³  ì‹¶ì€ ê²½í—˜ì´ ìˆë‚˜ìš”?""",
            "ì²¨ì‚­": """ìê¸°ì†Œê°œì„œ ì²¨ì‚­ í¬ì¸íŠ¸ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”:
âœ… êµ¬ì²´ì ì¸ ìˆ«ìì™€ ì„±ê³¼ í¬í•¨
âœ… ì§ë¬´ì™€ ì—°ê´€ëœ ê²½í—˜ ê°•ì¡°
âœ… ë¬¸ì¥ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ
âœ… ì§„ì •ì„± ìˆëŠ” ì§€ì›ë™ê¸°
íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‚´ìš©ì„ ë³´ë‚´ì£¼ì‹œë©´ ë” ìì„¸íˆ ë´ë“œë¦´ê²Œìš”!""",
            "ì‹œì‘": """ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ì‹œì‘í•´ë³¼ê¹Œìš”?
**Step 1. ê¸°ë³¸ ì •ë³´**
â€¢ ì§€ì› íšŒì‚¬:  # ì‚¬ìš©ìê°€ ì§€ì›í•  íšŒì‚¬ëª… ì…ë ¥
â€¢ ì§€ì› ì§ë¬´:  # ì‚¬ìš©ìê°€ ì§€ì›í•  ì§ë¬´ ì…ë ¥
â€¢ ê²½ë ¥ êµ¬ë¶„: (ì‹ ì…/ê²½ë ¥)  # ì§€ì›ìì˜ ê²½ë ¥ ì—¬ë¶€ ì„ íƒ"""
        }
"""
ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ AI ìê¸°ì†Œê°œì„œ ì½”ì¹­ í•¨ìˆ˜ ë° ëŒ€í™” UI ê´€ë ¨
"""

# ================= AI ì‘ë‹µ ìƒì„± (ê³„ì†) =================
# ì‚¬ìš©ìê°€ ë„ì›€ë§/ê°€ì´ë“œ ìš”ì²­ ì‹œ ë¯¸ë¦¬ ì •ì˜ëœ í…œí”Œë¦¿ ë°˜í™˜
guideline_keywords = ["ê°€ì´ë“œ", "ê°€ì´ë“œë¼ì¸", "ë„ì›€ë§", "ì‚¬ìš©ë²•", "ì–´ë–»ê²Œ"]
if any(keyword in user_input for keyword in guideline_keywords):
    return get_guideline()

# ê¸°ë³¸ í…œí”Œë¦¿ ì •ì˜
templates = {
    "default": """ì´ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤í˜•ìœ¼ë¡œ ë„ì™€ë“œë¦´ê²Œìš”!""",
    "ì²¨ì‚­": """ìê¸°ì†Œê°œì„œ ì²¨ì‚­ í¬ì¸íŠ¸:
âœ… êµ¬ì²´ì  ìˆ«ì/ì„±ê³¼ í¬í•¨
âœ… ì§ë¬´ ê´€ë ¨ ê²½í—˜ ê°•ì¡°
âœ… ë¬¸ì¥ ê°„ê²°/ëª…í™•
âœ… ì§„ì •ì„± ìˆëŠ” ì§€ì›ë™ê¸°""",
    "ì‹œì‘": """ìê¸°ì†Œê°œì„œ ì‘ì„± ì‹œì‘ ì•ˆë‚´:
â€¢ ì§€ì› íšŒì‚¬:
â€¢ ì§€ì› ì§ë¬´:
â€¢ ê²½ë ¥ êµ¬ë¶„: (ì‹ ì…/ê²½ë ¥)""",
    "ì˜ˆì‹œ": """ìê¸°ì†Œê°œì„œ ì˜ˆì‹œ:
"ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ íŒ€ì— ê¸°ì—¬í–ˆë˜ ì‚¬ë¡€ê°€ ìˆìŠµë‹ˆë‹¤."
â†’ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ë°©ì‹"""
}

# ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œì— ë”°ë¼ í…œí”Œë¦¿ ë°˜í™˜
if "ì²¨ì‚­" in user_input or "ìˆ˜ì •" in user_input:
    return templates["ì²¨ì‚­"]
elif "ì‹œì‘" in user_input or "ì²˜ìŒ" in user_input:
    return templates["ì‹œì‘"]
elif "ì˜ˆì‹œ" in user_input:
    return templates["ì˜ˆì‹œ"]
else:
    return templates["default"]

# ================= LLM ê¸°ë°˜ ì¼ë°˜ ì‘ë‹µ =================
try:
    # ì„ íƒ ëª¨ë¸ ë§¤í•‘
    model_map = {
        "GPT-4 (ë¬´ë£Œ)": "gpt-4o-mini",
        "GPT-4": "gpt-4o",
        "GPT-3.5": "gpt-3.5-turbo",
    }
    selected_model = st.session_state.basic_settings.get("model", "GPT-4 (ë¬´ë£Œ)")
    model_name = model_map.get(selected_model, "gpt-4o-mini")

    # LLM ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        api_key=st.session_state.get("api_key"),
        model=model_name,
        temperature=st.session_state.advanced_settings.get("creativity", 0.5),
    )

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •: ì „ë¬¸ ìê¸°ì†Œê°œì„œ ì½”ì¹˜ í†¤
    system_prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ìê¸°ì†Œê°œì„œ ì‘ì„± ì½”ì¹˜ì…ë‹ˆë‹¤.
    í†¤: {st.session_state.basic_settings['tone']}
    ìµœëŒ€ ê¸¸ì´: {st.session_state.basic_settings['length']}ì

    - êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
    - ì˜ˆì‹œ í¬í•¨
    - ì¹œê·¼í•˜ë©´ì„œ ì „ë¬¸ì ì¸ í†¤
    - ì´ëª¨ì§€ ìµœì†Œ ì‚¬ìš©"""

    # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬(txt, docx)
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.txt'):
                content = uploaded_file.read().decode('utf-8')
            elif uploaded_file.name.endswith('.docx') and DOCX_OK:
                doc = Document(uploaded_file)
                content = '\n'.join([p.text for p in doc.paragraphs])
            else:
                content = "íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            user_input = f"ë‹¤ìŒ ìê¸°ì†Œê°œì„œë¥¼ ê²€í† í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{content}\n\n{user_input}"
        except Exception as e:
            return f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", "{input}")])
    chain = LLMChain(llm=llm, prompt=prompt)
    response = chain.invoke({"input": user_input})
    return response.get("text", str(response))
except Exception as e:
    return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n{str(e)}"

# ================= ëŒ€í™” ì €ì¥ =================
def save_conversation() -> str:
    # í˜„ì¬ ì„¸ì…˜ ë©”ì‹œì§€ë¥¼ ì €ì¥
    content = ""
    for msg in st.session_state.messages:
        role = "ğŸ‘¤ ì‚¬ìš©ì" if msg["role"] == "user" else "ğŸ¤– AI ì½”ì¹˜"
        content += f"[{msg.get('time', '')}] {role}\n{msg['content']}\n\n"

    # íŒŒì¼ëª… ë° í˜•ì‹ ì„¤ì •
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ìì†Œì„œëŒ€í™”_{timestamp}"
    export = st.session_state.advanced_settings.get("export_format", "í…ìŠ¤íŠ¸ íŒŒì¼")

    # PDF ì €ì¥
    if export == "PDF ë¬¸ì„œ" and REPORTLAB_OK:
        bio = io.BytesIO()
        doc = SimpleDocTemplate(bio, pagesize=letter)
        styles = getSampleStyleSheet()
        story = [Paragraph(p, styles["Normal"]) for p in content.split('\n')]
        doc.build(story)
        file_data = bio.getvalue()
        mime = "application/pdf"
        ext = "pdf"

    # Word(docx) ì €ì¥
    elif export == "Word ë¬¸ì„œ" and DOCX_OK:
        doc = Document()
        doc.add_heading('AI ìê¸°ì†Œê°œì„œ ì½”ì¹­ ëŒ€í™”', 0)
        for para in content.split('\n'):
            doc.add_paragraph(para)
        bio = io.BytesIO()
        doc.save(bio)
        file_data = bio.getvalue()
        mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        ext = "docx"

    # HTML ì €ì¥
    elif export == "HTML ë¬¸ì„œ":
        file_data = f"<html><body><pre>{content}</pre></body></html>".encode("utf-8")
        mime = "text/html"
        ext = "html"

    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì €ì¥
    else:
        file_data = content.encode("utf-8")
        mime = "text/plain"
        ext = "txt"

    # ì„¸ì…˜ì— ì €ì¥
    st.session_state.saved_files.append(
        {
            "name": f"{filename}.{ext}",
            "date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "size": len(file_data),
            "data": file_data,
            "mime": mime,
        }
    )
    return f"{filename}.{ext}"

# ================= í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼ =================
st.set_page_config(page_title="AI ìê¸°ì†Œê°œì„œ ì½”ì¹­+", page_icon="ğŸ’¬", layout="wide")
MAIN = "#22C55E"  # ë©”ì¸ ìƒ‰
BG = "#F5FBFB"    # ë°°ê²½ìƒ‰
USER_BG = "#DCFCE7"  # ì‚¬ìš©ì ì±„íŒ… ë°°ê²½
BOT_BG = "#F3F4F6"   # AI ì±„íŒ… ë°°ê²½

# ì‚¬ìš©ì/ë´‡ UI ìŠ¤íƒ€ì¼ ì •ì˜
st.markdown(
    f"""
    <style>
        body {{ background:{BG}; }}
        .header {{position:sticky; top:0; background:{MAIN}; color:white; padding:34px; margin-top:0; margin-bottom:14px; border-radius:10px; z-index:10; font-size:4em; font-weight:900; text-align:center;}}
        .bubble-user {{background:{USER_BG}; padding:10px; border-radius:16px; margin:6px 0; text-align:right}}
        .bubble-bot {{background:{BOT_BG}; padding:10px; border-radius:16px; margin:6px 0; text-align:left}}
        .metric-box {{border-radius:14px; padding:10px; background:white; border:1px solid #e5e7eb}}
    </style>
    """,
    unsafe_allow_html=True,
)

# ================= ì‚¬ì´ë“œë°” ì„¤ì • =================
with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", value=os.getenv("OPENAI_API_KEY", ""), type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        st.session_state.api_key = api_key

    serp_key = st.text_input("SERPAPI_API_KEY (ì„ íƒ)", value=os.getenv("SERPAPI_API_KEY", ""), type="password")
    if serp_key:
        os.environ["SERPAPI_API_KEY"] = serp_key

    bing_key = st.text_input("BING_API_KEY (ì„ íƒ)", value=os.getenv("BING_API_KEY", ""), type="password")
    if bing_key:
        os.environ["BING_API_KEY"] = bing_key

    st.markdown("---")
    st.subheader("ëª¨ë¸/í†¤")
    models = ["GPT-4 (ë¬´ë£Œ)", "GPT-4", "GPT-3.5"]
    st.session_state.basic_settings["model"] = st.selectbox(
        "AI ëª¨ë¸", models, index=models.index(st.session_state.basic_settings.get("model", models[0]))
    )
    tones = ["ì „ë¬¸ì ", "ì¹œê·¼í•œ", "ê²©ì‹ ìˆëŠ”", "ìºì£¼ì–¼"]
    st.session_state.basic_settings["tone"] = st.selectbox(
        "ì‘ì„± í†¤", tones, index=tones.index(st.session_state.basic_settings.get("tone", tones[0]))
    )
    st.session_state.basic_settings["length"] = st.slider(
        "ê¸€ì ìˆ˜", min_value=300, max_value=2000, value=st.session_state.basic_settings.get("length", 800)
    )

    st.markdown("---")
    st.subheader("ì„¸ë¶€ ì„¤ì •")
    st.session_state.advanced_settings["creativity"] = st.slider(
        "ì°½ì˜ì„±", 0.0, 1.0, value=st.session_state.advanced_settings.get("creativity", 0.5)
    )
    export_options = ["PDF ë¬¸ì„œ", "Word ë¬¸ì„œ", "í…ìŠ¤íŠ¸ íŒŒì¼", "HTML ë¬¸ì„œ"]
    st.session_state.advanced_settings["export_format"] = st.selectbox(
        "ë‚´ë³´ë‚´ê¸° í˜•ì‹", export_options, index=export_options.index(st.session_state.advanced_settings.get("export_format", "PDF ë¬¸ì„œ"))
    )

# í˜ì´ì§€ ìƒë‹¨ í—¤ë”
st.markdown(f"<div class='header'><b>AI ìê¸°ì†Œê°œì„œ ì½”ì¹­ +</b></div>", unsafe_allow_html=True)

# ================= íƒ­ UI =================
tab_chat, tab_eval, tab_trend = st.tabs(["ğŸ’¬ ëŒ€í™”", "ğŸ§­ ìì†Œì„œ í‰ê°€", "ğŸ“ˆ íŠ¸ë Œë“œ/ê¸°ì—…"])

# --------- ğŸ’¬ ëŒ€í™” ---------
with tab_chat:
    col_title, col_button = st.columns([3, 1])
    with col_title:
        st.subheader("ì¼ë°˜ ì½”ì¹­ ëŒ€í™”")
    with col_button:
        if st.button("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ", use_container_width=True):
            st.session_state.show_guide = not st.session_state.show_guide

    # ê°€ì´ë“œ í‘œì‹œ
    if st.session_state.show_guide:
        st.markdown(
            "<div style='background-color: #f0f2f6; padding: 15px; border-radius: 15px; margin: 10px 0; border-left: 4px solid #22C55E;'>",
            unsafe_allow_html=True,
        )
        st.markdown(GUIDE, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“ íŒŒì¼ ì²¨ë¶€ (txt, docx)", type=["txt", "docx"], key="chat_file")

    # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f"<div class='bubble-user'>{msg['content']}</div>", unsafe_allow_html=True)
        else:
            content_html = msg['content'].replace('\n', '<br>')
            st.markdown(f"<div class='bubble-bot'>{content_html}</div>", unsafe_allow_html=True)

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input("ë©”ì‹œì§€ ì…ë ¥", key="chat_input")
    col_send, col_save = st.columns(2)
    if col_send.button("ì „ì†¡", use_container_width=True):
        if user_input.strip():
            # ì„¸ì…˜ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append(
                {"role": "user", "content": user_input.strip(), "time": datetime.datetime.now().strftime("%H:%M")}
            )
            # íšŒì‚¬ëª… íŒŒì‹± í›„ ìš”ì•½ ë˜ëŠ” ì¼ë°˜ ì‘ë‹µ
            company_name = try_parse_company_query(user_input)
            if company_name:
                response = summarize_company_from_csvs(company_name)
            else:
                response = get_ai_response(user_input, uploaded_file)
            # ì„¸ì…˜ì— AI ì‘ë‹µ ì €ì¥
            st.session_state.messages.append(
                {"role": "ai", "content": response, "time": datetime.datetime.now().strftime("%H:%M")}
            )
# ================= ëŒ€í™” ì €ì¥ & ë‹¤ìš´ë¡œë“œ =================
# ì‚¬ìš©ìê°€ 'ì „ì†¡' í›„ ëŒ€í™” ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ êµ¬í˜„
if col_save.button("ëŒ€í™” ì €ì¥", use_container_width=True):
    # save_conversation í•¨ìˆ˜ í˜¸ì¶œ â†’ ëŒ€í™” ë‚´ìš© íŒŒì¼ë¡œ ì €ì¥
    fname = save_conversation()
    st.success(f"{fname} ì €ì¥ë¨! ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")  # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥

# ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥
if st.session_state.saved_files:
    with st.expander("ğŸ“‚ ì €ì¥ëœ íŒŒì¼"):
        for i, file in enumerate(st.session_state.saved_files):
            st.write(f"ğŸ“„ {file['name']} ({file['date']}, {file['size']} bytes)")
            st.download_button(
                label="ë‹¤ìš´ë¡œë“œ",
                data=file["data"],          # íŒŒì¼ ë°ì´í„°
                file_name=file["name"],     # íŒŒì¼ ì´ë¦„
                mime=file["mime"],          # MIME íƒ€ì…
                key=f"download_{i}",        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ê³ ìœ  í‚¤
            )

# ================= ğŸ§­ ìì†Œì„œ í‰ê°€ íƒ­ =================
with tab_eval:
    st.subheader("ìì†Œì„œ í‰ê°€")  # íƒ­ ì œëª©
    colL, colR = st.columns([1, 1])  # ì¢Œ/ìš° 2 ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ

    # ----- ì™¼ìª½ ì»¬ëŸ¼: ì…ë ¥ ì˜ì—­ -----
    with colL:
        text = st.text_area("ìê¸°ì†Œê°œì„œ í…ìŠ¤íŠ¸")          # í‰ê°€í•  ìê¸°ì†Œê°œì„œ ì…ë ¥
        company = st.text_input("ì§€ì› íšŒì‚¬")             # ì§€ì› íšŒì‚¬ ì…ë ¥
        role = st.text_input("ì§€ì› ì§ë¬´")               # ì§€ì› ì§ë¬´ ì…ë ¥
        tone = st.selectbox("í†¤", ["ì „ë¬¸ì ", "ì¹œê·¼í•œ", "ê²©ì‹ ìˆëŠ”", "ìºì£¼ì–¼"], index=0)
        length = st.slider("ì¶œë ¥ ê¸¸ì´(ì)", 400, 1500, 900)  # ê°œì„ ì•ˆ ì¶œë ¥ ê¸¸ì´ ì„¤ì •
        run = st.button("í‰ê°€ ì‹¤í–‰", type="primary")   # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼

    # ----- ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: ì¶œë ¥ ì˜ì—­ -----
    with colR:
        st.markdown("**í‰ê°€ ì§€í‘œ**")
        st.caption("ì„±ê³¼Â·í–‰ë™Â·STARÂ·ê¸¸ì´Â·ìŠ¤í‚¬ì»¤ë²„ë¦¬ì§€Â·êµ°ë”ë”ê¸°")  # ì°¸ê³  ì§€í‘œ
        placeholder_metrics = st.empty()  # í‰ê°€ ì ìˆ˜ í‘œì‹œìš© placeholder
        improved_box = st.empty()         # ê°œì„ ì•ˆ í‘œì‹œìš© placeholder

    # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼ í´ë¦­ ì‹œ
    if run and text.strip():
        with st.spinner("í‰ê°€ ì¤‘â€¦"):
            scores = compute_resume_scores(text, role, company, skills)  # ì ìˆ˜ ê³„ì‚°

        # í‰ê°€ ì ìˆ˜ ì‹œê°í™”
        with placeholder_metrics.container():
            if VIZ_OK and PANDAS_OK:
                df_score = pd.DataFrame(
                    {
                        "í•­ëª©": ["ì´ì ", "ì„±ê³¼", "í–‰ë™", "STAR", "ê¸¸ì´", "ìŠ¤í‚¬", "ê°ì "],
                        "ì ìˆ˜": [
                            scores['ì´ì (0-100)'],
                            scores['ì„±ê³¼(ìˆ«ì)ë°€ë„']*100,
                            scores['í–‰ë™ì„±']*100,
                            scores['STARêµ¬ì¡°']*100,
                            scores['ê¸¸ì´ì ì •']*100,
                            scores['ìŠ¤í‚¬ì»¤ë²„ë¦¬ì§€']*100,
                            scores['êµ°ë”ë”ê¸°ê°ì ']*100,
                        ],
                    }
                )
                # Plotly ë§‰ëŒ€ ê·¸ë˜í”„ ì‹œê°í™”
                fig = px.bar(df_score, x="í•­ëª©", y="ì ìˆ˜", title="í‰ê°€ ê²°ê³¼(%)", range_y=[0, 100])
                st.plotly_chart(fig, use_container_width=True)
            st.json(scores)  # ì ìˆ˜ JSON í˜•íƒœë¡œ ì¶œë ¥

        # ê°œì„ ì•ˆ ì‘ì„±
        with st.spinner("ê°œì„ ì•ˆ ì‘ì„±â€¦"):
            improved = llm_improve(text, role, company, tone, length)  # LLM ê¸°ë°˜ ê°œì„ ì•ˆ ìƒì„±
        with improved_box.container():
            st.markdown("### âœï¸ ê°œì„ ì•ˆ")
            st.markdown(improved)

        # ìŠ¤í‚¬ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
        if PANDAS_OK and skills is not None:
            cov, matched = skill_coverage(text, skills)
            st.markdown("---")
            st.markdown("**ìŠ¤í‚¬ ë§¤ì¹­(ìµœê·¼ ìˆ˜ìš” ê¸°ì¤€)**")
            st.write(f"ì»¤ë²„ë¦¬ì§€: {cov*100:.1f}% / ë§¤ì¹­: {', '.join(matched) if matched else '(ì—†ìŒ)'}")
            # ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš” ì°¨íŠ¸
            if VIZ_OK:
                top_month = skills['month'].max() if 'month' in skills.columns else None
                kdf = skills.copy()
                if top_month:
                    kdf = kdf[kdf['month']==top_month]
                if 'job_count' in kdf.columns:
                    kdf = kdf.groupby('skill')['job_count'].sum().sort_values(ascending=False).head(15).reset_index()
                    st.altair_chart(
                        alt.Chart(kdf).mark_bar().encode(
                            x='job_count', 
                            y=alt.Y('skill', sort='-x')
                        ).properties(height=380, title=f"{top_month or ''} ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš”"),
                        use_container_width=True,
                    )

# ================= ğŸ“ˆ íŠ¸ë Œë“œ/ê¸°ì—… íƒ­ =================
with tab_trend:
    st.subheader("ìµœì‹  ìì†Œì„œ ë™í–¥ + ê¸°ì—… ì¸ì¬ìƒ/ìš”êµ¬ì—­ëŸ‰")
    c1, c2 = st.columns(2)

    # ----- ì™¼ìª½ ì»¬ëŸ¼: íšŒì‚¬/ì§ë¬´ ì…ë ¥ -----
    with c1:
        t_company = st.text_input("íšŒì‚¬ëª…", key="trend_company")
        t_role = st.text_input("ì§ë¬´", key="trend_role")
        do_crawl = st.button("ì›¹ ë¦¬ì„œì¹˜ ì‹¤í–‰")  # ì›¹ í¬ë¡¤ë§ ë²„íŠ¼

    # ----- ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: Tableau Public ë§í¬ ì…ë ¥ -----
    with c2:
        tableau_link = st.text_input("(ì„ íƒ) Tableau Public ë§í¬ ì„ë² ë“œ")

    # Tableau ë§í¬ê°€ ìˆìœ¼ë©´ iframeìœ¼ë¡œ í‘œì‹œ
    if tableau_link:
        st.markdown("---")
        st.markdown("**Tableau Public**")
        st.components.v1.iframe(tableau_link, height=520)

    st.markdown("---")
    st.markdown("### ğŸ“Š ë¡œì»¬ ë°ì´í„° ì¸ì‚¬ì´íŠ¸")

    # ë¡œì»¬ ì±„ìš©ê³µê³  ë°ì´í„° ì‹œê°í™”
    if PANDAS_OK and job_market is not None:
        if VIZ_OK and 'posted_date' in job_market.columns:
            try:
                jdf = job_market.copy()
                jdf['posted_date'] = pd.to_datetime(jdf['posted_date'], errors='coerce')
                ts = jdf.groupby(pd.Grouper(key='posted_date', freq='M'))['job_code'].nunique().reset_index()
                ts.columns = ['ì›”', 'ê³µê³ ìˆ˜']
                st.altair_chart(
                    alt.Chart(ts).mark_line(point=True).encode(
                        x='ì›”:T', 
                        y='ê³µê³ ìˆ˜:Q'
                    ).properties(height=280, title='ì›”ë³„ ì±„ìš©ê³µê³  ì¶”ì´'),
                    use_container_width=True,
                )
            except Exception:
                pass

    # ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš” ì°¨íŠ¸
    if PANDAS_OK and skills is not None and VIZ_OK:
        top_month = skills['month'].max() if 'month' in skills.columns else None
        kdf = skills.copy()
        if top_month:
            kdf = kdf[kdf['month']==top_month]
        if 'job_count' in kdf.columns:
            kdf = kdf.groupby('skill')['job_count'].sum().sort_values(ascending=False).head(15).reset_index()
            st.altair_chart(
                alt.Chart(kdf).mark_bar().encode(
                    x='job_count', 
                    y=alt.Y('skill', sort='-x')
                ).properties(height=360, title=f"{top_month or ''} ìƒìœ„ ê¸°ìˆ  ìˆ˜ìš”"),
                use_container_width=True,
            )

    # ì›¹ í¬ë¡¤ë§ ì‹¤í–‰ ì‹œ íšŒì‚¬ ì¸ì¬ìƒ/ìš”êµ¬ì—­ëŸ‰ ìˆ˜ì§‘
    if do_crawl and t_company:
        if not HTTP_OK:
            st.warning("requests/bs4 ë¯¸ì„¤ì¹˜ë¡œ ì›¹ ë¦¬ì„œì¹˜ë¥¼ ìƒëµí•©ë‹ˆë‹¤. 'pip install requests beautifulsoup4' ì„¤ì¹˜ í›„ ì¬ì‹œë„")
        else:
            with st.spinner("íšŒì‚¬ ì¸ì¬ìƒ/ìš”êµ¬ì—­ëŸ‰ ìˆ˜ì§‘ ì¤‘â€¦"):
                info = company_persona_and_requirements(t_company, t_role)  # í¬ë¡¤ë§ ê²°ê³¼
            # ì¸ì¬ìƒ í‘œì‹œ
            if info.get("ì¸ì¬ìƒ"):
                st.markdown("### ğŸ¢ ì¸ì¬ìƒ ìš”ì•½")
                st.write(info["ì¸ì¬ìƒ"])
            # ìš”êµ¬ì—­ëŸ‰ í‘œì‹œ
            if info.get("ìš”êµ¬ì—­ëŸ‰"):
                st.markdown("### âœ… ìš”êµ¬ì—­ëŸ‰(íŠ¸ë Œë“œ ê¸°ë°˜ ì œì•ˆ)")
                st.write(info["ìš”êµ¬ì—­ëŸ‰"])
            # ì¶œì²˜ í‘œì‹œ (ìµœëŒ€ 8ê°œ)
            if info.get("ì¶œì²˜"):
                st.markdown("#### ğŸ”— ì°¸ê³  ë§í¬")
                for s in info["ì¶œì²˜"][:8]:
                    st.markdown(f"- [{s.get('title','(ì œëª©ì—†ìŒ)')}]({s.get('url','')}) â€” {s.get('snippet','')}")
